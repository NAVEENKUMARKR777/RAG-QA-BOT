{"cells":[{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"data":{"text/plain":["{'cells': [{'cell_type': 'markdown',\n","   'metadata': {},\n","   'source': ['# QA Bot Pipeline\\n',\n","    'This notebook demonstrates the entire pipeline for a Retrieval-Augmented Generation (RAG) model for a Question Answering (QA) bot.\\n',\n","    'The bot processes uploaded documents, generates embeddings, and retrieves answers based on user queries.']},\n","  {'cell_type': 'code',\n","   'execution_count': 1,\n","   'metadata': {},\n","   'outputs': [],\n","   'source': ['# Install required libraries\\n',\n","    '!pip install pinecone-client cohere PyPDF2 python-dotenv']},\n","  {'cell_type': 'code',\n","   'execution_count': 2,\n","   'metadata': {},\n","   'outputs': [],\n","   'source': ['# Import necessary libraries\\n',\n","    'import os\\n',\n","    'import pinecone\\n',\n","    'import cohere\\n',\n","    'from PyPDF2 import PdfReader\\n',\n","    'from dotenv import load_dotenv\\n',\n","    '\\n',\n","    '# Load environment variables\\n',\n","    'load_dotenv()\\n',\n","    \"PINECONE_API_KEY = os.getenv('PINECONE_API_KEY')\\n\",\n","    \"COHERE_API_KEY = os.getenv('COHERE_API_KEY')\\n\",\n","    '\\n',\n","    '# Initialize Pinecone and Cohere clients\\n',\n","    'pinecone.init(api_key=PINECONE_API_KEY)\\n',\n","    'cohere_client = cohere.Client(api_key=COHERE_API_KEY)\\n',\n","    '\\n',\n","    '# Constants\\n',\n","    \"INDEX_NAME = 'your-index-name'  # Change to your index name\"]},\n","  {'cell_type': 'code',\n","   'execution_count': 3,\n","   'metadata': {},\n","   'outputs': [],\n","   'source': ['def extract_text_from_pdf(file_path):\\n',\n","    '    \"\"\"\\n',\n","    '    Extract text from a PDF file.\\n',\n","    '    \"\"\"\\n',\n","    \"    with open(file_path, 'rb') as f:\\n\",\n","    '        pdf_reader = PdfReader(f)\\n',\n","    '        text = \"\"\\n',\n","    '        for page in pdf_reader.pages:\\n',\n","    '            text += page.extract_text() or \"\"\\n',\n","    '    return text']},\n","  {'cell_type': 'code',\n","   'execution_count': 4,\n","   'metadata': {},\n","   'outputs': [],\n","   'source': ['def split_text_into_chunks(text, chunk_size=500):\\n',\n","    '    \"\"\"\\n',\n","    '    Split the text into manageable chunks.\\n',\n","    '    \"\"\"\\n',\n","    '    return [text[i:i + chunk_size] for i in range(0, len(text), chunk_size)]']},\n","  {'cell_type': 'code',\n","   'execution_count': 5,\n","   'metadata': {},\n","   'outputs': [],\n","   'source': ['def store_embeddings_in_pinecone(chunks):\\n',\n","    '    \"\"\"\\n',\n","    '    Store text embeddings in Pinecone.\\n',\n","    '    \"\"\"\\n',\n","    '    # Ensure the index exists\\n',\n","    '    if INDEX_NAME not in pinecone.list_indexes():\\n',\n","    '        pinecone.create_index(INDEX_NAME)\\n',\n","    '    index = pinecone.Index(INDEX_NAME)\\n',\n","    '    \\n',\n","    '    # Generate embeddings using Cohere\\n',\n","    '    embeddings = cohere_client.embed(texts=chunks).embeddings\\n',\n","    '    \\n',\n","    '    # Prepare data for Pinecone\\n',\n","    '    vectors = [(str(i), embeddings[i]) for i in range(len(embeddings))]\\n',\n","    '    \\n',\n","    '    # Upsert vectors into Pinecone\\n',\n","    '    index.upsert(vectors=vectors)']},\n","  {'cell_type': 'code',\n","   'execution_count': 6,\n","   'metadata': {},\n","   'outputs': [],\n","   'source': ['def retrieve_answer(question):\\n',\n","    '    \"\"\"\\n',\n","    '    Retrieve the answer to a question based on the stored embeddings in Pinecone.\\n',\n","    '    \"\"\"\\n',\n","    '    # Get embedding for the question\\n',\n","    '    question_embedding = cohere_client.embed(texts=[question]).embeddings[0]\\n',\n","    '    \\n',\n","    '    # Query Pinecone for the most relevant documents\\n',\n","    '    index = pinecone.Index(INDEX_NAME)\\n',\n","    '    query_response = index.query(queries=[question_embedding], top_k=3)\\n',\n","    '    \\n',\n","    '    # Generate answer using the relevant chunks\\n',\n","    \"    relevant_chunks = [match['id'] for match in query_response['matches']]\\n\",\n","    '    answer = cohere_client.generate(\\n',\n","    '        prompt=f\"Answer the question \\'{question}\\' using the following context: {relevant_chunks}\",\\n',\n","    '        max_tokens=100,\\n',\n","    '        temperature=0.5\\n',\n","    '    ).generations[0].text.strip()\\n',\n","    '    \\n',\n","    '    return answer']},\n","  {'cell_type': 'code',\n","   'execution_count': 7,\n","   'metadata': {},\n","   'outputs': [],\n","   'source': ['# Example usage\\n',\n","    '# Load a PDF file and process it\\n',\n","    \"file_path = 'path_to_your_document.pdf'  # Change to your document path\\n\",\n","    'text = extract_text_from_pdf(file_path)\\n',\n","    'chunks = split_text_into_chunks(text)\\n',\n","    'store_embeddings_in_pinecone(chunks)\\n',\n","    '\\n',\n","    '# Ask a question\\n',\n","    \"question = 'What is the main topic of the document?'\\n\",\n","    'answer = retrieve_answer(question)\\n',\n","    \"print(f'Question: {question}')\\n\",\n","    \"print(f'Answer: {answer}')\"]},\n","  {'cell_type': 'markdown',\n","   'metadata': {},\n","   'source': ['## Conclusion\\n',\n","    'This notebook provides a complete pipeline for a QA bot using Retrieval-Augmented Generation. It demonstrates how to process documents, generate embeddings, and retrieve answers using a vector database.']}],\n"," 'metadata': {'kernelspec': {'display_name': 'Python 3',\n","   'language': 'python',\n","   'name': 'python3'},\n","  'language_info': {'codemirror_mode': {'name': 'ipython', 'version': 3},\n","   'file_extension': '.py',\n","   'mimetype': 'text/x-python',\n","   'name': 'python',\n","   'nbconvert_exporter': 'python',\n","   'pygments_lexer': 'ipython3',\n","   'version': '3.8.5'}},\n"," 'nbformat': 4,\n"," 'nbformat_minor': 4}"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["{\n"," \"cells\": [\n","  {\n","   \"cell_type\": \"markdown\",\n","   \"metadata\": {},\n","   \"source\": [\n","    \"# QA Bot Pipeline\\n\",\n","    \"This notebook demonstrates the entire pipeline for a Retrieval-Augmented Generation (RAG) model for a Question Answering (QA) bot.\\n\",\n","    \"The bot processes uploaded documents, generates embeddings, and retrieves answers based on user queries.\"\n","   ]\n","  },\n","  {\n","   \"cell_type\": \"code\",\n","   \"execution_count\": 1,\n","   \"metadata\": {},\n","   \"outputs\": [],\n","   \"source\": [\n","    \"# Install required libraries\\n\",\n","    \"!pip install pinecone-client cohere PyPDF2 python-dotenv\"\n","   ]\n","  },\n","  {\n","   \"cell_type\": \"code\",\n","   \"execution_count\": 2,\n","   \"metadata\": {},\n","   \"outputs\": [],\n","   \"source\": [\n","    \"# Import necessary libraries\\n\",\n","    \"import os\\n\",\n","    \"import pinecone\\n\",\n","    \"import cohere\\n\",\n","    \"from PyPDF2 import PdfReader\\n\",\n","    \"from dotenv import load_dotenv\\n\",\n","    \"\\n\",\n","    \"# Load environment variables\\n\",\n","    \"load_dotenv()\\n\",\n","    \"PINECONE_API_KEY = os.getenv('PINECONE_API_KEY')\\n\",\n","    \"COHERE_API_KEY = os.getenv('COHERE_API_KEY')\\n\",\n","    \"\\n\",\n","    \"# Initialize Pinecone and Cohere clients\\n\",\n","    \"pinecone.init(api_key=PINECONE_API_KEY)\\n\",\n","    \"cohere_client = cohere.Client(api_key=COHERE_API_KEY)\\n\",\n","    \"\\n\",\n","    \"# Constants\\n\",\n","    \"INDEX_NAME = 'your-index-name'  # Change to your index name\"\n","   ]\n","  },\n","  {\n","   \"cell_type\": \"code\",\n","   \"execution_count\": 3,\n","   \"metadata\": {},\n","   \"outputs\": [],\n","   \"source\": [\n","    \"def extract_text_from_pdf(file_path):\\n\",\n","    \"    \\\"\\\"\\\"\\n\",\n","    \"    Extract text from a PDF file.\\n\",\n","    \"    \\\"\\\"\\\"\\n\",\n","    \"    with open(file_path, 'rb') as f:\\n\",\n","    \"        pdf_reader = PdfReader(f)\\n\",\n","    \"        text = \\\"\\\"\\n\",\n","    \"        for page in pdf_reader.pages:\\n\",\n","    \"            text += page.extract_text() or \\\"\\\"\\n\",\n","    \"    return text\"\n","   ]\n","  },\n","  {\n","   \"cell_type\": \"code\",\n","   \"execution_count\": 4,\n","   \"metadata\": {},\n","   \"outputs\": [],\n","   \"source\": [\n","    \"def split_text_into_chunks(text, chunk_size=500):\\n\",\n","    \"    \\\"\\\"\\\"\\n\",\n","    \"    Split the text into manageable chunks.\\n\",\n","    \"    \\\"\\\"\\\"\\n\",\n","    \"    return [text[i:i + chunk_size] for i in range(0, len(text), chunk_size)]\"\n","   ]\n","  },\n","  {\n","   \"cell_type\": \"code\",\n","   \"execution_count\": 5,\n","   \"metadata\": {},\n","   \"outputs\": [],\n","   \"source\": [\n","    \"def store_embeddings_in_pinecone(chunks):\\n\",\n","    \"    \\\"\\\"\\\"\\n\",\n","    \"    Store text embeddings in Pinecone.\\n\",\n","    \"    \\\"\\\"\\\"\\n\",\n","    \"    # Ensure the index exists\\n\",\n","    \"    if INDEX_NAME not in pinecone.list_indexes():\\n\",\n","    \"        pinecone.create_index(INDEX_NAME)\\n\",\n","    \"    index = pinecone.Index(INDEX_NAME)\\n\",\n","    \"    \\n\",\n","    \"    # Generate embeddings using Cohere\\n\",\n","    \"    embeddings = cohere_client.embed(texts=chunks).embeddings\\n\",\n","    \"    \\n\",\n","    \"    # Prepare data for Pinecone\\n\",\n","    \"    vectors = [(str(i), embeddings[i]) for i in range(len(embeddings))]\\n\",\n","    \"    \\n\",\n","    \"    # Upsert vectors into Pinecone\\n\",\n","    \"    index.upsert(vectors=vectors)\"\n","   ]\n","  },\n","  {\n","   \"cell_type\": \"code\",\n","   \"execution_count\": 6,\n","   \"metadata\": {},\n","   \"outputs\": [],\n","   \"source\": [\n","    \"def retrieve_answer(question):\\n\",\n","    \"    \\\"\\\"\\\"\\n\",\n","    \"    Retrieve the answer to a question based on the stored embeddings in Pinecone.\\n\",\n","    \"    \\\"\\\"\\\"\\n\",\n","    \"    # Get embedding for the question\\n\",\n","    \"    question_embedding = cohere_client.embed(texts=[question]).embeddings[0]\\n\",\n","    \"    \\n\",\n","    \"    # Query Pinecone for the most relevant documents\\n\",\n","    \"    index = pinecone.Index(INDEX_NAME)\\n\",\n","    \"    query_response = index.query(queries=[question_embedding], top_k=3)\\n\",\n","    \"    \\n\",\n","    \"    # Generate answer using the relevant chunks\\n\",\n","    \"    relevant_chunks = [match['id'] for match in query_response['matches']]\\n\",\n","    \"    answer = cohere_client.generate(\\n\",\n","    \"        prompt=f\\\"Answer the question '{question}' using the following context: {relevant_chunks}\\\",\\n\",\n","    \"        max_tokens=100,\\n\",\n","    \"        temperature=0.5\\n\",\n","    \"    ).generations[0].text.strip()\\n\",\n","    \"    \\n\",\n","    \"    return answer\"\n","   ]\n","  },\n","  {\n","   \"cell_type\": \"code\",\n","   \"execution_count\": 7,\n","   \"metadata\": {},\n","   \"outputs\": [],\n","   \"source\": [\n","    \"# Example usage\\n\",\n","    \"# Load a PDF file and process it\\n\",\n","    \"file_path = 'path_to_your_document.pdf'  # Change to your document path\\n\",\n","    \"text = extract_text_from_pdf(file_path)\\n\",\n","    \"chunks = split_text_into_chunks(text)\\n\",\n","    \"store_embeddings_in_pinecone(chunks)\\n\",\n","    \"\\n\",\n","    \"# Ask a question\\n\",\n","    \"question = 'What is the main topic of the document?'\\n\",\n","    \"answer = retrieve_answer(question)\\n\",\n","    \"print(f'Question: {question}')\\n\",\n","    \"print(f'Answer: {answer}')\"\n","   ]\n","  },\n","  {\n","   \"cell_type\": \"markdown\",\n","   \"metadata\": {},\n","   \"source\": [\n","    \"## Conclusion\\n\",\n","    \"This notebook provides a complete pipeline for a QA bot using Retrieval-Augmented Generation. It demonstrates how to process documents, generate embeddings, and retrieve answers using a vector database.\"\n","   ]\n","  }\n"," ],\n"," \"metadata\": {\n","  \"kernelspec\": {\n","   \"display_name\": \"Python 3\",\n","   \"language\": \"python\",\n","   \"name\": \"python3\"\n","  },\n","  \"language_info\": {\n","   \"codemirror_mode\": {\n","    \"name\": \"ipython\",\n","    \"version\": 3\n","   },\n","   \"file_extension\": \".py\",\n","   \"mimetype\": \"text/x-python\",\n","   \"name\": \"python\",\n","   \"nbconvert_exporter\": \"python\",\n","   \"pygments_lexer\": \"ipython3\",\n","   \"version\": \"3.8.5\"\n","  }\n"," },\n"," \"nbformat\": 4,\n"," \"nbformat_minor\": 4\n","}"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.0"}},"nbformat":4,"nbformat_minor":2}
